#!/usr/bin/env python
# coding: utf-8

# Retail Orders ELT Analytics Project
# Workflow: Extract -> Load -> Transform -> Analyze

import pandas as pd
import zipfile
import sqlalchemy as sal
import kaggle  # Used Kaggle API to download dataset

# Step 1: Extract dataset from Kaggle
!kaggle datasets download ankitbansal06/retail-orders -f orders.csv

# Unzip the downloaded file
with zipfile.ZipFile('orders.csv.zip', 'r') as zip_ref:
    zip_ref.extractall()  # Extract CSV to current directory

# Step 2: Load dataset into Python
# Handle missing values marked as 'Not Available' or 'unknown'
df = pd.read_csv('orders.csv', na_values=['Not Available','unknown'])

# Step 3: Clean column names
# Standardize: lowercase and replace spaces with underscores
df.columns = df.columns.str.lower().str.replace(' ', '_')

# Step 4: Derive new metrics
# Compute profit for each order
df['profit'] = df['sale_price'] - df['cost_price']

# Optional: discount calculations
# df['discount'] = df['list_price'] * df['discount_percent'] * 0.01
# df['sale_price'] = df['list_price'] - df['discount']

# Step 5: Convert date columns
df['order_date'] = pd.to_datetime(df['order_date'], format="%Y-%m-%d")

# Step 6: Drop unnecessary columns
df.drop(columns=['list_price','cost_price','discount_percent'], inplace=True)

# Step 7: Load data into SQL Server (SSMS)
engine = sal.create_engine(
    'mssql+pyodbc://HANUMAN\SQLEXPRESS/master?driver=ODBC+Driver+17+for+SQL+Server'
)
conn = engine.connect()

# Step 8: Load data to SQL Server table
df.to_sql('df_orders', con=conn, index=False, if_exists='replace')

print("Data loaded successfully into SQL Server. Ready for SQL-based transformations and analytics.")
